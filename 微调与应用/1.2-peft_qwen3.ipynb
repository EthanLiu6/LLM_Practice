{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b328e6d-682b-4ff4-b5f9-ac28d8cac941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.qwen3 import Qwen3ForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from peft import LoraConfig, TaskType\n",
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3aa24db-077e-413f-ad6a-c05e3c09bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import modeling_utils\n",
    "if modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\", \"colwise\", 'rowwise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351687a7-507e-43fb-b1db-d211e76e6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen3 = '/Users/ethanliu/Documents/models/Qwen/Qwen3-0.6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fbca50-748c-422f-bb5b-0d320585e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "qwen3_model = Qwen3ForCausalLM.from_pretrained(\n",
    "    qwen3,\n",
    "    torch_dtype='float16',\n",
    "    device_map='mps')\n",
    "# qwen3_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68917173-a156-4571-b4ab-045c68979703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 下面的total_param和origin_train_param要提前定义查看，不然后面使用lora会共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a82e5db-83d8-4542-afc7-cfc29ae6a2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55511474609375"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_param = sum([param.numel() for name, param in qwen3_model.named_parameters()]) / 1024 / 1024 / 1024\n",
    "total_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ddc6bf-68ad-48f7-944b-ccaf0f3e0090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55511474609375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_train_param = sum(param.numel() for name, param in qwen3_model.named_parameters() if param.requires_grad==True) / 1024 / 1024 / 1024\n",
    "origin_train_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb2c5e-c455-49b6-a632-85383cfd8407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0be6750f-d668-469c-89e8-ff1376c56d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7655f37a-e0c4-48ce-bd26-dd4f5077a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = get_peft_model(model=qwen3_model, peft_config=lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3682f8-3441-41a4-8cb1-f92ab774ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d2a676-f934-4a2e-9ad7-834dd4c74145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5572509765625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_param = sum([param.numel() for name, param in lora_model.named_parameters()]) / 1024 / 1024 / 1024\n",
    "lora_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ab6206-cbb7-4866-b5a1-32cebb266bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5572509765625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_total_param = sum([param.numel() for name, param in qwen3_model.named_parameters()]) / 1024 / 1024 / 1024\n",
    "new_total_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0128acf4-0c24-4004-a630-f0fb011a07bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00213623046875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lora_param = sum(param.numel() for name, param in lora_model.named_parameters() if param.requires_grad==True) / 1024 / 1024/ 1024\n",
    "train_lora_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a9d864d-7162-4922-baa3-84fe4344a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38482682792743267"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_lora_param / origin_train_param) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eda21f41-c70d-4f9f-960a-ec7e3b536f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight --- torch.float16\n",
      "model.layers.0.self_attn.q_proj.base_layer.weight --- torch.float16\n",
      "tensor(0.6445, device='mps:0', dtype=torch.float16)    grad_is: False\n",
      "model.layers.0.self_attn.q_proj.lora_A.default.weight --- torch.float32\n",
      "tensor(0.0312, device='mps:0', grad_fn=<MaxBackward1>)    grad_is: True\n",
      "model.layers.0.self_attn.q_proj.lora_B.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.k_proj.base_layer.weight --- torch.float16\n",
      "model.layers.0.self_attn.k_proj.lora_A.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.k_proj.lora_B.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.v_proj.base_layer.weight --- torch.float16\n",
      "model.layers.0.self_attn.v_proj.lora_A.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.v_proj.lora_B.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.o_proj.base_layer.weight --- torch.float16\n",
      "model.layers.0.self_attn.o_proj.lora_A.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.o_proj.lora_B.default.weight --- torch.float32\n",
      "model.layers.0.self_attn.q_norm.weight --- torch.float16\n",
      "model.layers.0.self_attn.k_norm.weight --- torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight --- torch.float16\n",
      "model.layers.0.mlp.up_proj.weight --- torch.float16\n",
      "model.layers.0.mlp.down_proj.weight --- torch.float16\n",
      "model.layers.0.input_layernorm.weight --- torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight --- torch.float16\n",
      "model.layers.1.self_attn.q_proj.base_layer.weight --- torch.float16\n"
     ]
    }
   ],
   "source": [
    "for name, param in qwen3_model.named_parameters():\n",
    "    print(name, '---', param.dtype)\n",
    "    if 'model.layers.0.self_attn.q_proj.lora_A.default.weight' == name:\n",
    "        print(param.max(), '   grad_is:', param.requires_grad)\n",
    "    if 'model.layers.0.self_attn.q_proj.base_layer.weight' == name:\n",
    "        print(param.max(), '   grad_is:', param.requires_grad)\n",
    "    if 'layers.1' in name:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33ded0-cc96-4863-b956-9616d0b86e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12nlp",
   "language": "python",
   "name": "p12nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
